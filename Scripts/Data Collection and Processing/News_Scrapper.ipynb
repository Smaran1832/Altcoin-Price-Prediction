{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Investing.com Scrapping"
      ],
      "metadata": {
        "id": "Tt4h5Aj2BA9W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woOQxDRdAyFh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# links = []\n",
        "df = pd.DataFrame({\"Date\":[],\"Headline\":[]})\n",
        "for d in range(1,3000):\n",
        "  url='https://www.investing.com/news/cryptocurrency-news/' + str(d)\n",
        "  response = requests.get(url)\n",
        "\n",
        "  soup2 = BeautifulSoup(response.text, 'html.parser')\n",
        "  try:\n",
        "    headlines = soup2.find('div',{'class':'largeTitle'}).find_all('div',{'class':'textDiv'})\n",
        "    for x in headlines:\n",
        "      sponser = x.find('span',{'class':'sponsoredBadge arial_11'})\n",
        "      if (sponser != None):\n",
        "        continue\n",
        "      link = 'https://www.investing.com/' + x.a['href']\n",
        "      url3 = link\n",
        "      response1 = requests.get(url3)\n",
        "      soup3 = BeautifulSoup(response1.text, 'html.parser')\n",
        "      try:\n",
        "        headline = soup3.find('h1',{'class':'articleHeader'})\n",
        "        date = soup3.find('div',{'class':'contentSectionDetails'}).find('span') \n",
        "        print(headline.text)\n",
        "        print(date.text)\n",
        "      except:\n",
        "        continue\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/cryptocurrency_project/investing_news.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coindesk Scrapping"
      ],
      "metadata": {
        "id": "d0gm5VJFBu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "links = []\n",
        "df = pd.DataFrame({\"Date\":[],\"Headline\":[]})\n",
        "for d in range(1,1000):\n",
        "  url='https://www.coindesk.com/tag/news/' + str(d) + '/'\n",
        "  response = requests.get(url)\n",
        "\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  headlines = soup.find_all('div',{'class':'article-cardstyles__StyledWrapper-q1x8lc-0 hKWAzg article-card default'})\n",
        "  for x in headlines:\n",
        "      category = x.find('a',{'class':'category'})\n",
        "      if category.text == \"Podcasts\":\n",
        "        continue\n",
        "      if category.text == \"Policy\":\n",
        "        continue\n",
        "      headline = x.find('a',{'class':'card-title'})\n",
        "      link = 'https://www.coindesk.com' + headline['href']\n",
        "      url1 = link\n",
        "      response = requests.get(url1)\n",
        "      soup1 = BeautifulSoup(response.text, 'html.parser')        \n",
        "      headline = soup1.find('h1',{'class':'typography__StyledTypography-owin6q-0 fPbJUO'})\n",
        "      date = soup1.find('span',{'class':'typography__StyledTypography-owin6q-0 fUOSEs'})\n",
        "      try:\n",
        "        df.loc[len(df.index)] = [date.text,headline.text] \n",
        "      except:\n",
        "        print(\"exception\")\n",
        "        continue\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/cryptocurrency_project/coindesk_news.csv\")"
      ],
      "metadata": {
        "id": "eoDOBh5PBtyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forbes News Scrapping"
      ],
      "metadata": {
        "id": "rnDMXpRfCMYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import exception\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "HTMLFile = open(\"Crypto & Blockchain.html\",\"r\")\n",
        "contents = HTMLFile.read()\n",
        "soup8 = BeautifulSoup(contents, 'html.parser')\n",
        "headlines = soup8.find('div',{'class':'chansec-stream__items'}).find_all('div',{'class':'stream-item__text'})\n",
        "df = pd.DataFrame({\"Date\":[],\"Headline\":[]})\n",
        "for x in headlines:\n",
        "  date = x.find('div',{'class':'stream-item__date'})\n",
        "  head = x.find('a',{'class':'stream-item__title'})\n",
        "  try:\n",
        "    df.loc[len(df.index)] = [date.text,head.text] \n",
        "  except:\n",
        "    print(exception)\n",
        "    continue\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/cryptocurrency_project/forbes_news.csv\")"
      ],
      "metadata": {
        "id": "KvTNw5XbCJIW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}